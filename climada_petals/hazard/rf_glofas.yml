# Holds all information relevant for a climada evaluation
---
# The directory associated with the DataManager.
# (Is not required to hold any data, but can be used for loading data from.)
data_dir: ~/coding/climada_petals/climada_petals/hazard/rf_glofas_data

# Keyword arguments that are used to set up the DataManager and PlotManager
data_manager:
  out_dir: "_output"
  out_dir_kwargs:
    exist_ok: true

  load_cfg:
    flood_maps:
      loader: xr_dataarray
      glob_str: flood_maps.nc
      required: True
      engine: h5netcdf

    glofas_historical_gumbel_fit:
      loader: xr_dataset
      glob_str: glofas-historical-gumbel-fit.nc
      required: True
      engine: h5netcdf

plot_manager:
  raise_exc: true
  out_dir: '{timestamp:}/'  # also the default
  default_creator: base
  shared_creator_init_kwargs:
    default_ext: pdf

# The "evaluation" routine, orchestrated by the PlotManager but not requiring
# to actually output any plots.
# (This can also be the path to a separate file.)
eval:
  # .. Shared configs .........................................................
  # ... starting with a dot: ignored by default, used only in `based_on`

  .shared:
    # Need to define a "plot" function ... but does not need to do anything
    # module: __main__
    module: climada_petals.hazard.rf_glofas
    plot_func: store_flood_depth_in_dm

    # Configure the DAG framework
    use_dag: true
    # compute_only: ~   # can also pass a list of tags here, e.g. [result]
    compute_only: [flood_depth, data_manager]
    dag_visualization:
      when:
        on_compute_success: true  # -> always saves a DAG representation plot

  .dag.cache.use:
    dag_options:
      file_cache_defaults:
        read:
          enabled: true
          load_options:
            engine: h5netcdf
        write:
          enabled: true
          min_compute_time: 1.
          storage_options:
            engine: h5netcdf

  # An evaluation task with default cache use (and some explicit cases)
  with_cache:
    based_on:
      - .shared
      - .dag.cache.use  # â‡’ cache used on all nodes with compute time > 1s

    # Define variables for spatial extent
    .spatial_extent:
      west: &lon_min 66
      east: &lon_max 77
      north: &lat_max 32
      south: &lat_min 23

      meta_operations:
        # Shortcut for spatial subsection
        sel_lon_lat:
          transform:
            - operation: .sel
              args: [ !arg 0 ]
              kwargs:
                latitude: !slice [ *lat_max , *lat_min ]
                longitude: !slice [ *lon_min , *lon_max ]

    select:
      flood_maps: flood_maps
      gumbel_fits: glofas_historical_gumbel_fit

    transform:
      - operation: download_glofas_discharge
        args: [forecast, "2022-08-10", "2022-08-11", 2]
        kwargs:
          area: [*lat_max , *lon_min , *lat_min , *lon_max ]
          # leadtime_hour: ["24", "48", "72"]
          format: grib

      # Take the leadtime maximum
      # - operation: .max
      #   args: [!dag_prev ]
      #   kwargs:
      #     dim: step
      #   tag: discharge

      # Compute quantiles of the ensemble
      - operation: .quantile
        args: [!dag_prev , [0.1, 0.5, 0.9]]
        kwargs:
          dim: number
        tag: discharge

      # Extract loc and scale from GEV fit dataset
      - getitem: [!dag_tag gumbel_fits, loc]
        tag: gev_loc

      - getitem: [!dag_tag gumbel_fits, scale]
        tag: gev_scale

      # Compute the return period
      - operation: return_period
        args: [!dag_tag discharge, !dag_tag gev_loc, !dag_tag gev_scale]
        tag: return_period

      # Interpolate onto finer grid
      - operation: interpolate_space
        args: [!dag_tag return_period, !dag_tag flood_maps]
        tag: return_period_interpolated
        file_cache:
          read:
            load_options:
              chunks: {time: -1, number: -1, step: -1}

      # Compute flood depth
      - operation: flood_depth
        args: [!dag_tag return_period_interpolated, !dag_tag flood_maps]
        tag: flood_depth
        file_cache:
          write: true

      # Pass the data manager to the plot function so we can store the result in it
      - pass: !dag_tag dm
        tag: data_manager
